{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the csv file 8037\n",
      "Training started...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_2 (Lambda)                (None, 160, 320, 3)   0           lambda_input_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)        (None, 65, 320, 3)    0           lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 31, 158, 24)   1824        cropping2d_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_7 (Convolution2D)  (None, 14, 77, 36)    21636       convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_8 (Convolution2D)  (None, 5, 37, 48)     43248       convolution2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 5, 37, 48)     0           convolution2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_9 (Convolution2D)  (None, 3, 35, 64)     27712       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_10 (Convolution2D) (None, 1, 33, 64)     36928       convolution2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1, 33, 64)     0           convolution2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 2112)          0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 512)           1081856     flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 64)            32832       dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 64)            0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            650         dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             11          dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,246,697\n",
      "Trainable params: 1,246,697\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "6133/6429 [===========================>..] - ETA: 8s - loss: 0.7849 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RSavirig\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6457/6429 [==============================] - 224s - loss: 0.7497 - val_loss: 0.0498\n",
      "Epoch 2/10\n",
      "6144/6429 [===========================>..] - ETA: 8s - loss: 0.0708 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d1343863f7a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m \u001b[0mmainfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-d1343863f7a4>\u001b[0m in \u001b[0;36mmainfn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;31m#print('generator invoked train {} valid {}'.format(train_generator, valid_generator))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[0mmainfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-d1343863f7a4>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(train_generator, valid_generator, len_train, len_valid)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlen_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training complete!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total time for training {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    936\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1552\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1899\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1900\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1901\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 766\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 964\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1014\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\carnd-term1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    reads the file using csv library and returns rows in the file\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    with open(filename) as csvfile:\n",
    "        data_rows = csv.reader(csvfile)\n",
    "        for row in data_rows:\n",
    "            lines.append(row)\n",
    "    return lines\n",
    "\n",
    "def crop_images(X, y):\n",
    "    \"\"\"\n",
    "    This method calculates the top and bottom percentages and crops the image\n",
    "    Resulting shape is (72, 320, 3)\n",
    "    No. of Output Images = No. of Input Images\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    top_percent = 0.4\n",
    "    bottom_percent = 0.15\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        ind_img = X[i]\n",
    "        top = int(np.ceil(ind_img.shape[0] * top_percent))\n",
    "        bottom = ind_img.shape[0] - int(np.ceil(ind_img.shape[0] * bottom_percent))\n",
    "        cropped_img = ind_img[top:bottom, :]\n",
    "        images.append(cropped_img)\n",
    "        steering_angles.append(y[i])\n",
    "    return images, steering_angles\n",
    "\n",
    "#Without resizing gave better results, hence don't use this\n",
    "def resize_images(X, y):\n",
    "    \"\"\"\n",
    "    This method resizes the images to height=66, widht=200\n",
    "    No. of Output Images = No. of Input Images\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        resized = cv2.resize(X[i], (200, 66))\n",
    "        images.append(resized)\n",
    "        steering_angles.append(y[i])\n",
    "    return images, steering_angles\n",
    "\n",
    "    \n",
    "def apply_gamma(X, y):\n",
    "    \"\"\"\n",
    "    This method applies gamma filter to the input images\n",
    "    Observe the gamma images are added to the original data set\n",
    "    No. of Output Images = 2 * (No. of Input Images)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        gamma = np.random.uniform(0.7, 1.7)\n",
    "        inv_gamma = 1 / gamma\n",
    "        map_table = np.array([((i/255.0)**inv_gamma)*255 for i in np.arange(0,256)])\n",
    "        transformed_img = cv2.LUT(X[i], map_table)\n",
    "        images.append(X[i])\n",
    "        steering_angles.append(y[i])\n",
    "        images.append(transformed_img)\n",
    "        steering_angles.append(y[i])\n",
    "    return images, steering_angles\n",
    "\n",
    "def vary_brightness(X, y):\n",
    "    \"\"\"\n",
    "    This method alters the brightness of the image by a random value\n",
    "    uses HSV color space as V represents brightness\n",
    "    No. of Output Images = No. of Input Images\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        # HSV (Hue, Saturation, Value) - Value is brightness\n",
    "        hsv_img = cv2.cvtColor(X[i], cv2.COLOR_RGB2HSV)\n",
    "        random_value = 1.0 + 0.6 * (np.random.rand() - 0.5)\n",
    "        hsv_img[:,:,2] =  hsv_img[:,:,2] * random_value\n",
    "        transformed_img =  cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)\n",
    "        images.append(transformed_img)\n",
    "        steering_angles.append(y[i])\n",
    "    return images, steering_angles\n",
    "\n",
    "    \n",
    "def flip_images_and_add(X, y):\n",
    "    \"\"\"\n",
    "    This method flips the input images\n",
    "    Flips are done only for those images where steering angles are outside the range of (-0.1, +0,1)\n",
    "    This means straight or near straight steering angle images are not flipped as it doens't add any value\n",
    "    No. of Output Images > No. of Input Images\n",
    "    \"\"\"\n",
    "    #print('size before', len(X))\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        #print('less or greater {}'.format(y[i]))\n",
    "        images.append(X[i])\n",
    "        steering_angles.append(y[i])\n",
    "        #Flip only those images where there are curves\n",
    "        if y[i] < -0.1 or y[i] > 0.1 :\n",
    "            images.append(cv2.flip(X[i], 1))\n",
    "            steering_angles.append(y[i] * -1.0)\n",
    "    return images, steering_angles\n",
    "\n",
    "def translate(X, y, range_x, range_y):\n",
    "    \"\"\"\n",
    "    This method randomly translates the image in any direction \n",
    "    and calculates the corresponding change in the steering angle\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    steering_angles = []\n",
    "    for i in range(len(X)):\n",
    "        trans_x = range_x * (np.random.rand() - 0.5)\n",
    "        trans_y = range_y * (np.random.rand() - 0.5)\n",
    "        transformed_angle = y[i] + trans_x * 0.002\n",
    "        trans_m = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "        height, width = X[i].shape[:2]\n",
    "        transformed_img = cv2.warpAffine(X[i], trans_m, (width, height))\n",
    "        images.append(X[i])\n",
    "        steering_angles.append(y[i])\n",
    "        images.append(transformed_img)\n",
    "        steering_angles.append(transformed_angle)\n",
    "    return images, steering_angles\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def data_generator(rows, validation_flag, batch_size):\n",
    "    \"\"\"\n",
    "    This is the Python Generator that reads values in chunks\n",
    "    and makes it possible to run in modest CPUs\n",
    "    \"\"\"\n",
    "    correction_factor = 0.20\n",
    "    path = 'trainingdata/IMG/'\n",
    "    len_rows = len(rows)\n",
    "    rows = shuffle(rows)\n",
    "    while 1:\n",
    "        for offset in range(0, len_rows, batch_size):\n",
    "            batch_rows = rows[offset:offset+batch_size]\n",
    "            images = []\n",
    "            steering_values = []\n",
    "            #print('rows in batch', len(batch_rows))\n",
    "            for line in batch_rows:\n",
    "                \n",
    "                center_image_path = line[0]\n",
    "                left_image_path = line[1]\n",
    "                right_image_path = line[2]\n",
    "\n",
    "                center_image_name = center_image_path.split('/')[-1] #Last token [-1] is the image\n",
    "                left_image_name = left_image_path.split('/')[-1]\n",
    "                right_image_name = right_image_path.split('/')[-1]\n",
    "\n",
    "                center_image_bgr = cv2.imread(path+center_image_name)\n",
    "                left_image_bgr   = cv2.imread(path+left_image_name)\n",
    "                right_image_bgr = cv2.imread(path+right_image_name)\n",
    "                \n",
    "                #Converting from BGR to RGB space as simulator reads RGB space\n",
    "                center_image = cv2.cvtColor(center_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                left_image   = cv2.cvtColor(left_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                right_image = cv2.cvtColor(right_image_bgr, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                \n",
    "\n",
    "                steering_value = float(line[3])\n",
    "                left_steering_value = steering_value + correction_factor\n",
    "                right_steering_value = steering_value - correction_factor\n",
    "                \n",
    "                images.append(cv2.GaussianBlur(center_image, (3, 3), 0))\n",
    "#                 images.append(center_image)\n",
    "                steering_values.append(steering_value)\n",
    "\n",
    "                images.append(cv2.GaussianBlur(left_image, (3, 3), 0))\n",
    "#                 images.append(left_image)\n",
    "                steering_values.append(left_steering_value)\n",
    "                \n",
    "                images.append(cv2.GaussianBlur(right_image, (3, 3), 0))\n",
    "#                 images.append(right_image)\n",
    "                steering_values.append(right_steering_value)\n",
    "                \n",
    "            \n",
    "            X_train, y_train = images, steering_values\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "            #Augmenting & Pre-processing\n",
    "            #X_train, y_train = crop_images(X_train, y_train)\n",
    "            #X_train, y_train = resize_images(X_train, y_train)\n",
    "            X_train, y_train = translate(X_train, y_train, 100, 10)\n",
    "            X_train, y_train = flip_images_and_add(X_train, y_train)\n",
    "            X_train, y_train = vary_brightness(X_train, y_train)\n",
    "            X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "            X_train = np.array(X_train)\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            yield X_train, y_train\n",
    "\n",
    "        \n",
    "\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout, Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "#Architecture based on NVIDIA\n",
    "def train_model(train_generator, valid_generator, len_train, len_valid):\n",
    "    \"\"\"\n",
    "    This method contains the definition of the model\n",
    "    It also calls methods to train and validate the data set\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Training started...')\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape=(72, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape=(160, 320, 3)))\n",
    "    model.add(Cropping2D(cropping=((70, 25), (0, 0))))\n",
    "    #model.add(Reshape((55, 135)))\n",
    "    model.add(Convolution2D(24, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Convolution2D(36, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Convolution2D(48, 5, 5, activation='elu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='elu'))\n",
    "    model.add(Dense(64, activation='elu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.fit_generator(train_generator, samples_per_epoch= len_train, validation_data=valid_generator, nb_val_samples=len_valid, nb_epoch=10)\n",
    "    print('Training complete!')\n",
    "    print('Total time for training {:.3f}'.format(time.time() - start_time))\n",
    "    model.save('model.h5')\n",
    "\n",
    "    \n",
    "\n",
    "def mainfn():\n",
    "    \"\"\"\n",
    "    This is the main function that kicks-off the process\n",
    "    \"\"\"\n",
    "    data_rows = read_file('./trainingdata/driving_log.csv')\n",
    "    print('Length of the csv file {}'.format(len(data_rows)))\n",
    "    \n",
    "    rows_train, rows_valid = train_test_split(data_rows, test_size=0.2)\n",
    "    #print('splitting done {} {}'.format(len(rows_train), len(rows_valid)))\n",
    "    \n",
    "    train_generator = data_generator(rows_train, False, batch_size = 32)\n",
    "    valid_generator = data_generator(rows_valid, True, batch_size = 32)\n",
    "    #print('generator invoked train {} valid {}'.format(train_generator, valid_generator))\n",
    "    \n",
    "    train_model(train_generator, valid_generator, len(rows_train), len(rows_valid))\n",
    "\n",
    "#Calling the mainfn() to kick-off the process\n",
    "mainfn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
